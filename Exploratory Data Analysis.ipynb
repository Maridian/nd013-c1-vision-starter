{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the dataset\n",
    "\n",
    "\n",
    "In this notebook, we will perform an EDA (Exploratory Data Analysis) on the processed Waymo dataset (data in the `processed` folder). In the first part, you will create a function to display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading unweighted datasets: ['Data/processed']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['Data/processed']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(\"Data/processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'imshow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/app/project/Exploratory Data Analysis.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f666c616d626f79616e745f676f6c64776173736572227d/app/project/Exploratory%20Data%20Analysis.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mfor\u001b[39;00m width \u001b[39min\u001b[39;00m parsed_dataset\u001b[39m.\u001b[39mtake(\u001b[39m1\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f666c616d626f79616e745f676f6c64776173736572227d/app/project/Exploratory%20Data%20Analysis.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     image_np \u001b[39m=\u001b[39m width\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f666c616d626f79616e745f676f6c64776173736572227d/app/project/Exploratory%20Data%20Analysis.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     plt\u001b[39m.\u001b[39;49mimshow(image_np)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f666c616d626f79616e745f676f6c64776173736572227d/app/project/Exploratory%20Data%20Analysis.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f666c616d626f79616e745f676f6c64776173736572227d/app/project/Exploratory%20Data%20Analysis.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m#print(width)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f666c616d626f79616e745f676f6c64776173736572227d/app/project/Exploratory%20Data%20Analysis.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     \n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f666c616d626f79616e745f676f6c64776173736572227d/app/project/Exploratory%20Data%20Analysis.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# Iterate over the dataset and decode the image\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f666c616d626f79616e745f676f6c64776173736572227d/app/project/Exploratory%20Data%20Analysis.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39m#plt.imshow(image_np)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f666c616d626f79616e745f676f6c64776173736572227d/app/project/Exploratory%20Data%20Analysis.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m     \u001b[39m#plt.show()\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'imshow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "# Create a TFRecordDataset\n",
    "dataset = tf.data.TFRecordDataset('Data/processed/segment-10017090168044687777_6380_000_6400_000_with_camera_labels.tfrecord')\n",
    "\n",
    "# Parse the records using the feature description\n",
    "def _parse_function(example_proto):\n",
    "    feature_description = {\n",
    "        #'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    parsed_example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    #image = tf.image.decode_jpeg(parsed_example['image'], channels=3)\n",
    "    return parsed_example['image/encoded']\n",
    "\n",
    "# Apply the parse function to the dataset\n",
    "parsed_dataset = dataset.map(_parse_function)\n",
    "for width in parsed_dataset.take(1):\n",
    "    image_np = width.numpy()\n",
    "    plt.imshow(image_np)\n",
    "    plt.show()\n",
    "    #print(width)\n",
    "    \n",
    "# Iterate over the dataset and decode the image\n",
    "#for record in parsed_dataset:\n",
    "    #image_raw = record['image']\n",
    "\n",
    "    # Decode the image from the raw bytes\n",
    "   #image = tf.image.decode_image(image_raw)\n",
    "\n",
    "    # Convert the image tensor to a NumPy array\n",
    "    #image_np = image.numpy()\n",
    "\n",
    "    # Visualize the image\n",
    "    #plt.imshow(image_np)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Iterate over the dataset and decode the image\n",
    "image_raw = dataset['image']\n",
    "    #label = record['label']\n",
    "\n",
    "    # Decode the image from the raw bytes\n",
    "image = tf.image.decode_image(image_raw)\n",
    "\n",
    "    # Convert the image tensor to a NumPy array\n",
    "image_np = image.numpy()\n",
    "\n",
    "    # Visualize the image\n",
    "plt.imshow(image_np)\n",
    "    #plt.title(f'Label: {label}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a function to display an image and the bounding boxes\n",
    "\n",
    "Implement the `display_instances` function below. This function takes a batch as an input and display an image with its corresponding bounding boxes. The only requirement is that the classes should be color coded (eg, vehicles in red, pedestrians in blue, cyclist in green)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_instances(batch):\n",
    "    \"\"\"\n",
    "    This function takes a batch from the dataset and display the image with \n",
    "    the associated bounding boxes.\n",
    "    \"\"\"\n",
    "    # ADD CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display 10 images \n",
    "\n",
    "Using the dataset created in the second cell and the function you just coded, display 10 random images with the associated bounding boxes. You can use the methods `take` and `shuffle` on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STUDENT SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional EDA\n",
    "\n",
    "In this last part, you are free to perform any additional analysis of the dataset. What else would like to know about the data?\n",
    "For example, think about data distribution. So far, you have only looked at a single file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
